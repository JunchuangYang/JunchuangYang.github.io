<html>
  <head>
    <title>机器学习绪论 - Y&#39;s Blog</title>
    <link href='/images/fav.png' rel='shortcut icon'>
<link href='/atom.xml' rel='alternate' type='application/rss+xml'>
<link rel="stylesheet" href="/css/style.css">
<link rel="stylesheet" href="/css/highlight.css">
<link rel="stylesheet" href="/css/responsive.css">
<script src="/js/jquery.js"></script>
<script src="/js/basics.js"></script>
<meta content='width=device-width, initial-scale=1.0, user-scalable=no' name='viewport'>
<meta content='text/html; charset=utf-8' http-equiv='content-type'>


  </head>
  <body>
    <header>
  <a id='go-back-home' href='/'><img src='/images/scribble.png' alt='Home' width='53' height='59'></a>
  <p>Y&#39;s Blog</p>
  <p>Salted fish without dreams</p>
</header>

    <div id='container'>
      <div class='block'>
  
    <a class='main' href='/'>Home</a>
  
    <a class='main' href='/about'>About</a>
  
    <a class='main' href='https://github.com/JunchuangYang'>Github</a>
  
</div>

      <section class='paging'>
  
  
    <div class='right'>
      <a href='/2018/09/28/总结_2018年9月/'>
        ›
      </a>
    </div>
  
</section>

      <div class='content'>
        <section class='post'>
          <h1>
            <div class='date'>2018-10-13</div>
            机器学习绪论
          </h1>
          <h2 id="1引言"><a href="#1引言" class="headerlink" title="1引言"></a><strong>1引言</strong></h2><p>&ensp;&ensp;&ensp;&ensp;什么是机器学习？机器学习致力于研究如何通过计算的手段，利用经验来改善系统自身的性能。在计算机系统中，“经验”通常以“数据”形式存在，因此，机器学习所研究的主要内容，是关于在计算机上从数据中产生“模型”（model）的算法，即<strong>“学习算法”</strong>。有了学习算法，我们把经验数据提供给它，它就能基于这些数据产生模型；在面对新情况时，模型会给我们提供相应的判断，如果说计算机科学是研究关于“算法”的学问，那么类似的，可以说机器学习是研究关于“学习算法”的学问。</p>
<h2 id="2基本术语"><a href="#2基本术语" class="headerlink" title="2基本术语"></a><strong>2基本术语</strong></h2><p>&ensp;&ensp;&ensp;&ensp;数据集：数据记录的集合称为一个数据集。<br>&ensp;&ensp;&ensp;&ensp;样本：数据集中每条记录是关于一个事件或对象的描述，称为一个样本。<br>&ensp;&ensp;&ensp;&ensp;属性（特征）：反应事件或对象在某方面的表现或性质的事项。<br>&ensp;&ensp;&ensp;&ensp;属性值：属性上的取值。<br>&ensp;&ensp;&ensp;&ensp;特征向量：我们把西瓜的三个属性“色泽”，“根蒂”，“敲声”作为三个坐标轴，则它们张成一个用于描述西瓜的三围空间，每个西瓜都可在这个空间中找到自己的坐标位置。由于空间中的每一个点对应一个坐标向量，因此我们也把一个示例称为一个<strong>“特征向量”</strong>。<br>&ensp;&ensp;&ensp;&ensp;分类：若我们预测的是离散值，此类学习任务称为<strong>“分类”</strong> 。<br>&ensp;&ensp;&ensp;&ensp;回归：若预测的是连续值，此类学习任务称为<strong>“回归”</strong>。<br>&ensp;&ensp;&ensp;&ensp;根据训练数据是否拥有标记信息，学习任务可大致分为两大类：<strong>监督学习</strong>和<strong>无监督学习</strong>。分类和回归是前者的代表，而<strong>聚类</strong>是后者的代表。<br>&ensp;&ensp;&ensp;&ensp;学得的模型适用于新样本的能力，称为 <strong>泛化</strong>能力。具有强泛化能力的模型能很好地适用于整个样本空间。通常假设样本空间中全体样本服从一个未知“分布” <em>D</em> ，我们获得的每一个样本都是独立地从这个分布上获得的，即独立同分布。一般而言，训练样本越多，我们得到的关于<em>D</em>的信息越多，这样就越有可能通过学习获得具有强泛化能力的模型。</p>
<h2 id="3假设空间"><a href="#3假设空间" class="headerlink" title="3假设空间"></a><strong>3假设空间</strong></h2><p>&ensp;&ensp;&ensp;&ensp;归纳和演绎是科学推理的两大基本手段。前者是从特殊到一般的泛化过程，即从具体的事实归结出一般性规律；后者则是从一般到特殊的泛化过程，即从基础原理推演出具体状况。例如，在数学公理系统中，基于一组公理和推理规则推导出与之相洽的定理，这是演绎；而从样例中学习显然是一个归纳的过程，因此亦称为归纳学习。  </p>
<h2 id="4归纳偏好"><a href="#4归纳偏好" class="headerlink" title="4归纳偏好  "></a><strong>4归纳偏好  </strong></h2><p>&ensp;&ensp;&ensp;&ensp;机器学习算法在学习过程中对某种类型假设的偏好，称为“归纳偏好”。任何一个有效的机器学习的算法必有其归纳偏好，否则它将被假设空间中看似在训练集上“等效”的假设所迷惑，而无法产生确定的学习结果。可以想象一下，如果没有偏好，我们的西瓜学习算法产生的模型每次在进行预测时，随机抽取训练集上等效的假设，那么对这个新瓜（色泽=青绿；根蒂=蜷缩；敲声=沉闷），学得的模型时而告诉我们它是好的，时而告诉我们它是不好的，这样的学习结果是没有意义的。我们一般使用<strong>奥卡姆剃刀（若有多个假设与观察一致，则选择最简单的那个。）</strong>原则来指引算法做出正确偏好的选择。<br>&ensp;&ensp;&ensp;&ensp;举个例子：<br><img src="https://i.imgur.com/EPPtUbY.png" alt=""><br>&ensp;&ensp;&ensp;&ensp;归纳偏好的例子在上述图中可能更直观，假设上图中有六个数据点，算法LA基于某种归纳偏好产生了对应于曲线A的模型，算法LB基于另一种归纳偏好产生了对应于曲线B的模型。根据奥卡姆剃刀原则，我们假设曲线“更平滑”意味着“更简单”，这是我们就有理由确信算法La比算法LB要好。确实，在上图中，曲线A与训练集外的样本更一致，A的泛化能力更强。<br>&ensp;&ensp;&ensp;&ensp;但是，我们希望且相信LA比LB更好，但会不会出现下图中的情况，在这种情况下：B是不是表现的更好？<br><img src="https://i.imgur.com/qWkf0fu.png" alt=""><br><em>（中间省略一系列推到过程，我实在看不懂。）</em> 根据公式进行推导后的结果是：总误差与学习算法无关。也就是无论使用哪种算法，他们的期望值竟然相同。这就是<strong>没有免费的午餐定理（No Free Lunch Theorem,简称NFL定理）</strong> 。<br>&ensp;&ensp;&ensp;&ensp;既然所有的学习算法的期望性都跟随机的差不多，那还有什么好学的？我们需要注意到，NFL定理有一个重要的前提：所有“问题”出现的机会相同、或所有问题同等重要。但实际情形并不是这样。很多时候，我们只关注自己正在试图解决的问题，希望为他找到一个解决方案，至于这个解决方案在别的问题、甚至在相似的问题上是否有好的方案，我们并不关心。<br>&ensp;&ensp;&ensp;&ensp;NFL定理最重要的寓意是让我们清楚的认识到，脱离具体问题，空谈“什么学习算法更好”毫无意义，因为若考虑所有潜在的问题，则所有学习算法都一样好。要谈论算法的相对优劣，必须要只对具体的学习问题；在某些问题上表现好的算法，在另一些问题上可能表现的不尽如人意，学习算法自身的归纳偏好与为题是否相配，往往会起到决定性的作用。</p>
<p>&ensp;&ensp;&ensp;&ensp;参考文献：周志华 著. 机器学习, 北京: 清华大学出版社, 2016年1月.</p>

          <br>
<p>Y&#39;s Blog</p>
<p><img src='/images/scribble3.png' alt='scribble'></p>

        </section>
      </div>
      
      <div class='block'>
  
    <a class='main' href='/'>Home</a>
  
    <a class='main' href='/about'>About</a>
  
    <a class='main' href='https://github.com/JunchuangYang'>Github</a>
  
</div>

    </div>
    <footer>
  <span class='muted'>&copy; Junchuang Yang. All Rights Reserved.</span><br>
  <a href='https://github.com/saintwinkle/hexo-theme-scribble' class='muted'>built with Hexo using Scribble theme</a>
  <br>
  <br>
   <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  <span id="busuanzi_container_site_pv">
    "��վ�ܷ�����"<span id="busuanzi_value_site_pv"></span>"��"
  </span>
  <br>
  <img src='/images/scribble2.png' alt='scribble' />
</footer>

  </body>
</html>
